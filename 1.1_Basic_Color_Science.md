# 1.1 Basic Color Science

## Color Perception Fundamentals

Human vision is based on the tristimulus theory, which states that the human eye perceives color through three types of cone cells. These cones, often labeled as S, M, and L, are sensitive to different wavelengths of light: short, medium, and long, respectively.  The brain interprets the relative stimulation of these three cone types as a specific color.  This fundamental principle is the basis for most color models used in digital imaging.

The CIE (Commission Internationale de l'Éclairage) 1931 XYZ color space is a mathematically defined color space that represents all colors visible to the average human observer. It's based directly on the tristimulus response of the human eye.  Any color can be defined by three values (X, Y, Z), which correspond to the stimulation levels of the three cone types.  The XYZ color space is device-independent, meaning it doesn't rely on the characteristics of any particular display or capture device. It serves as a fundamental reference for color management.

## Mathematics of Color Models

### RGB

RGB is an *additive* color model.  This means that colors are created by *adding* different amounts of red, green, and blue light.  When all three colors are combined at full intensity, the result is white. When all three are absent, the result is black.  This is in contrast to *subtractive* color models (like CMYK used in printing), where colors are created by subtracting light from a white background.

In digital systems, each color channel (Red, Green, Blue) is typically represented by a numerical value.  The range of this value depends on the *bit depth*.  For example:

*   **8-bit color:** Each channel has 256 possible values (0-255).  0 represents the absence of that color, and 255 represents the maximum intensity. This allows for 256 x 256 x 256 = 16,777,216 different colors.
*   **10-bit color:** Each channel has 1024 possible values (0-1023). This allows for over 1 billion colors.
*   **12-bit color:** Each channel has 4096 possible values (0-4095). This allows for over 68 billion colors.
*   **16-bit color:** Each channel has 65536 possible values (0-65535).

Higher bit depths provide more granular control over color and reduce the likelihood of banding artifacts (visible steps between colors).

### XYZ

The CIE 1931 XYZ color space is device-independent and serves as a foundation for defining other color spaces.  RGB color spaces (like Rec.709, DCI-P3, Rec.2020) are defined by their *primaries*, which are the specific red, green, and blue colors that the device can produce.  These primaries are defined by their chromaticity coordinates (x, y) within the CIE XYZ color space.

The transformation from an RGB color space to XYZ is a linear transformation, represented by a 3x3 matrix.  This matrix is specific to each RGB color space and is derived from the chromaticity coordinates of its primaries and white point.  The general form of the transformation is:

```
[X]   [ Rx  Gx  Bx ] [R]
[Y] = [ Ry  Gy  By ] [G]
[Z]   [ Rz  Gz  Bz ] [B]
```

Where:

*   R, G, B are the linear RGB values.
*   X, Y, Z are the CIE XYZ values.
*   Rx, Ry, Rz, Gx, Gy, Gz, Bx, By, Bz are the elements of the transformation matrix.

The inverse transformation (from XYZ to RGB) uses the inverse of this matrix.

## Digital Sensors and Color Capture

Digital camera sensors capture color using a Color Filter Array (CFA). The most common type of CFA is the Bayer filter, which uses a pattern of red, green, and blue filters arranged over individual photosites (pixels) on the sensor.  The Bayer pattern typically has twice as many green filters as red or blue filters, because the human eye is more sensitive to green light.

Each photosite on the sensor measures the intensity of light that passes through its corresponding color filter.  This means that each photosite only captures information about one color (red, green, or blue).  The raw data from the sensor is therefore a mosaic of individual color measurements.

To create a full-color image, a process called *demosaicing* (or *debayering*) is used.  Demosaicing algorithms interpolate the missing color information at each photosite, using the values from neighboring photosites.  There are many different demosaicing algorithms, varying in complexity and quality.  More sophisticated algorithms can produce sharper images with fewer artifacts (like color fringing or moiré patterns).

The quality of color capture is also influenced by the sensor's:

*   **Dynamic Range:** The range of light intensities the sensor can capture, from the darkest shadows to the brightest highlights.  A wider dynamic range allows for more detail to be captured in both shadows and highlights.
*   **Noise Characteristics:**  All sensors produce some level of noise (random variations in pixel values).  Noise is more noticeable in darker areas of the image.  Sensors with lower noise levels produce cleaner images.
*   **Color Filter Array Design:** The specific spectral sensitivities of the color filters in the CFA affect the accuracy of color reproduction.
* **Bit Depth:** The bit depth of the sensor's analog-to-digital converter (ADC) determines the number of discrete levels that can be used to represent the intensity of light at each photosite. Higher bit depth allows for more precise color representation.

The combination of these factors determines the overall color fidelity and image quality of a digital camera.
